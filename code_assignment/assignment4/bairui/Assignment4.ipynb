{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "\n",
    "def pre_process(data):\n",
    "    sentences = list()\n",
    "    tags = list()\n",
    "    sentence = list()\n",
    "    tag = list()\n",
    "    for line in data:\n",
    "        if line == '\\n':\n",
    "            if sentence:\n",
    "                sentences.append(sentence)\n",
    "                tags.append(tag)\n",
    "                sentence = list()\n",
    "                tag = list()\n",
    "        else:\n",
    "            elements = line.split()\n",
    "            if elements[0] == '-DOCSTART-':\n",
    "                continue\n",
    "            sentence.append(elements[0].upper())\n",
    "            tag.append(elements[-1])\n",
    "    if sentence:\n",
    "        sentences.append(sentence)\n",
    "        tags.append(tag)\n",
    "\n",
    "    return list(zip(sentences, tags))\n",
    "\n",
    "\n",
    "class Glove_embedding():\n",
    "    def __init__(self, train_zip, test_zip, trained_dict=None):\n",
    "        if trained_dict is None:\n",
    "            trained_dict = dict()\n",
    "        self.dict_words = dict()\n",
    "        self.trained_dict = trained_dict\n",
    "        train_zip.sort(key=lambda x: len(x[0]))\n",
    "        test_zip.sort(key=lambda x: len(x[0]))\n",
    "        self.train_x, self.train_y = zip(*train_zip)\n",
    "        self.test_x, self.test_y = zip(*test_zip)\n",
    "        self.train_x_matrix = list()\n",
    "        self.test_x_matrix = list()\n",
    "        self.train_y_matrix = list()\n",
    "        self.test_y_matrix = list()\n",
    "        self.len_words = 1\n",
    "        self.len_tag = 3\n",
    "        self.longest = 0\n",
    "        self.embedding = list()\n",
    "        self.tag_dict = {'<pad>': 0, '<begin>': 1, '<end>': 2}\n",
    "\n",
    "    def get_words(self):\n",
    "        self.embedding.append([0] * 50)\n",
    "        for term in self.train_x:\n",
    "            for word in term:  # Process every word\n",
    "                if word not in self.dict_words:\n",
    "                    self.dict_words[word] = len(self.dict_words)+1\n",
    "                    if word in self.trained_dict:\n",
    "                        self.embedding.append(self.trained_dict[word])\n",
    "                    else:\n",
    "                        # print(word)\n",
    "                        # raise Exception(\"words not found!\")\n",
    "                        self.embedding.append([0] * 50)\n",
    "        for term in self.test_x:\n",
    "            for word in term:  # Process every word\n",
    "                if word not in self.dict_words:\n",
    "                    self.dict_words[word] = len(self.dict_words)+1\n",
    "                    if word in self.trained_dict:\n",
    "                        self.embedding.append(self.trained_dict[word])\n",
    "                    else:\n",
    "                        # print(word)\n",
    "                        # raise Exception(\"words not found!\")\n",
    "                        self.embedding.append([0] * 50)\n",
    "        for tags in self.train_y:\n",
    "            for tag in tags:\n",
    "                if tag not in self.tag_dict:\n",
    "                    self.tag_dict[tag] = len(self.tag_dict)\n",
    "        for tags in self.test_y:\n",
    "            for tag in tags:\n",
    "                if tag not in self.tag_dict:\n",
    "                    self.tag_dict[tag] = len(self.tag_dict)\n",
    "        self.len_tag = len(self.tag_dict)\n",
    "        self.len_words = len(self.dict_words)+1\n",
    "\n",
    "    def get_id(self):\n",
    "        for term in self.train_x:\n",
    "            item = [self.dict_words[word] for word in term]\n",
    "            self.longest = max(self.longest, len(item))\n",
    "            self.train_x_matrix.append(item)\n",
    "        for term in self.test_x:\n",
    "            item = [self.dict_words[word] for word in term]\n",
    "            self.longest = max(self.longest, len(item))\n",
    "            self.test_x_matrix.append(item)\n",
    "        for tags in self.train_y:\n",
    "            item = [self.tag_dict[tag] for tag in tags]\n",
    "            self.train_y_matrix.append(item)\n",
    "        for tags in self.test_y:\n",
    "            item = [self.tag_dict[tag] for tag in tags]\n",
    "            self.test_y_matrix.append(item)\n",
    "\n",
    "\n",
    "class ClsDataset(Dataset):\n",
    "    def __init__(self, sentence, tag):\n",
    "        self.sentence = sentence\n",
    "        self.tag = tag\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.sentence[item], self.tag[item]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tag)\n",
    "\n",
    "\n",
    "def collate_fn(batch_data):\n",
    "    sentence, tag = zip(*batch_data)\n",
    "    sentences = [torch.LongTensor(sent) for sent in sentence]\n",
    "    padded_sents = pad_sequence(sentences, batch_first=True, padding_value=0)\n",
    "    tags = [torch.LongTensor(t) for t in tag]\n",
    "    padded_tags = pad_sequence(tags, batch_first=True, padding_value=0)\n",
    "    return torch.LongTensor(padded_sents), torch.LongTensor(padded_tags)\n",
    "\n",
    "\n",
    "def get_batch(x, y, batch_size):\n",
    "    dataset = ClsDataset(x, y)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, drop_last=True, collate_fn=collate_fn)\n",
    "    return dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Named_Entity_Recognition(nn.Module):\n",
    "    \n",
    "    def __init__(self, len_feature, len_words, len_hidden, type_num, pad_id, start_id, end_id, weight=None,\n",
    "                 drop_out=0.5):\n",
    "        super(Named_Entity_Recognition, self).__init__()\n",
    "        self.len_feature = len_feature\n",
    "        self.len_words = len_words\n",
    "        self.len_hidden = len_hidden\n",
    "        self.dropout = nn.Dropout(drop_out)\n",
    "        if weight is None:\n",
    "            x = nn.init.xavier_normal_(torch.Tensor(len_words, len_feature))\n",
    "            self.embedding = nn.Embedding(num_embeddings=len_words, embedding_dim=len_feature, _weight=x).to(device)\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(num_embeddings=len_words, embedding_dim=len_feature, _weight=weight).to(device)\n",
    "        self.lstm = nn.LSTM(input_size=len_feature, hidden_size=len_hidden, batch_first=True, bidirectional=True).to(device)\n",
    "        self.fc = nn.Linear(2 * len_hidden, type_num).to(device)\n",
    "        self.crf = CRF(type_num, pad_id, start_id, end_id).to(device)\n",
    "\n",
    "    def forward(self, x, tags, mask):\n",
    "        mask = mask.int()\n",
    "        x = self.embedding(x)\n",
    "        x = self.dropout(x)\n",
    "        self.lstm.flatten_parameters()\n",
    "        x, _ = self.lstm(x)\n",
    "        scores = self.fc(x)\n",
    "        loss = self.crf(scores, tags, mask)\n",
    "        return loss\n",
    "\n",
    "    def predict(self, x, mask):\n",
    "        mask = mask.int()\n",
    "        x = self.embedding(x)\n",
    "        x = self.dropout(x)\n",
    "        self.lstm.flatten_parameters()\n",
    "        x, _ = self.lstm(x)\n",
    "        scores = self.fc(x)\n",
    "\n",
    "        return self.crf.predict(scores, mask)\n",
    "\n",
    "\n",
    "class CRF(nn.Module):\n",
    "\n",
    "    def __init__(self, type_num, pad_id, start_id, end_id):\n",
    "        super(CRF, self).__init__()\n",
    "        self.type_num = type_num\n",
    "        self.pad_id = pad_id\n",
    "        self.start_id = start_id\n",
    "        self.end_id = end_id\n",
    "\n",
    "        transition = torch.zeros(type_num, type_num)\n",
    "        transition[:, start_id] = -10000.0\n",
    "        transition[end_id, :] = -10000.0\n",
    "        transition[:, pad_id] = -10000.0\n",
    "        transition[pad_id, :] = -10000.0\n",
    "        transition[pad_id, pad_id] = 0.0\n",
    "        transition[pad_id, :end_id] = 0.0\n",
    "\n",
    "        self.transition = nn.Parameter(transition).to(device)\n",
    "\n",
    "    def forward(self, scores, tags, mask):\n",
    "        true_prob = self.true_prob(scores, tags, mask)\n",
    "        total_prob = self.total_prob(scores, mask)\n",
    "        return -torch.sum(true_prob - total_prob)\n",
    "\n",
    "    def true_prob(self, scores, tags, mask):\n",
    "        batch_size, sequence_len = tags.shape\n",
    "        true_prob = torch.zeros(batch_size).to(device)\n",
    "\n",
    "        first_tag = tags[:, 0]\n",
    "        last_tag_index = mask.sum(1) - 1\n",
    "        last_tag = torch.gather(tags, 1, last_tag_index.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "        tran_score = self.transition[self.start_id, first_tag]\n",
    "        tag_score = torch.gather(scores[:, 0], 1, first_tag.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "        true_prob += tran_score + tag_score\n",
    "\n",
    "        for i in range(1, sequence_len):\n",
    "            non_pad = mask[:, i]\n",
    "            pre_tag = tags[:, i - 1]\n",
    "            curr_tag = tags[:, i]\n",
    "\n",
    "            tran_score = self.transition[pre_tag, curr_tag]\n",
    "            tag_score = torch.gather(scores[:, i], 1, curr_tag.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "            true_prob += tran_score * non_pad + tag_score * non_pad\n",
    "\n",
    "        true_prob += self.transition[last_tag, self.end_id]\n",
    "\n",
    "        return true_prob\n",
    "\n",
    "    def total_prob(self, scores, mask):\n",
    "        batch_size, sequence_len, num_tags = scores.shape\n",
    "        log_sum_exp_prob = self.transition[self.start_id, :].unsqueeze(0) + scores[:, 0]\n",
    "        for i in range(1, sequence_len):\n",
    "            every_log_sum_exp_prob = list()\n",
    "            for j in range(num_tags):\n",
    "                tran_score = self.transition[:, j].unsqueeze(0)\n",
    "                tag_score = scores[:, i, j].unsqueeze(1)\n",
    "\n",
    "                prob = tran_score + tag_score + log_sum_exp_prob\n",
    "\n",
    "                every_log_sum_exp_prob.append(torch.logsumexp(prob, dim=1))\n",
    "\n",
    "            new_prob = torch.stack(every_log_sum_exp_prob).t()\n",
    "\n",
    "            non_pad = mask[:, i].unsqueeze(-1)\n",
    "            log_sum_exp_prob = non_pad * new_prob + (1 - non_pad) * log_sum_exp_prob\n",
    "\n",
    "        tran_score = self.transition[:, self.end_id].unsqueeze(0)\n",
    "        return torch.logsumexp(log_sum_exp_prob + tran_score, dim=1)\n",
    "\n",
    "    def predict(self, scores, mask):\n",
    "        batch_size, sequence_len, num_tags = scores.shape\n",
    "        total_prob = self.transition[self.start_id, :].unsqueeze(0) + scores[:, 0]\n",
    "        tags = torch.cat([torch.tensor(range(num_tags)).view(1, -1, 1) for _ in range(batch_size)], dim=0).to(device)\n",
    "        for i in range(1, sequence_len):\n",
    "            new_prob = torch.zeros(batch_size, num_tags).to(device)\n",
    "            new_tag = torch.zeros(batch_size, num_tags, 1).to(device)\n",
    "            for j in range(num_tags):\n",
    "                prob = total_prob + self.transition[:, j].unsqueeze(0) + scores[:, i, j].unsqueeze(1)\n",
    "                max_prob, max_tag = torch.max(prob, dim=1)\n",
    "                new_prob[:, j] = max_prob\n",
    "                new_tag[:, j, 0] = max_tag\n",
    "\n",
    "            non_pad = mask[:, i].unsqueeze(-1)\n",
    "            total_prob = non_pad * new_prob + (1 - non_pad) * total_prob\n",
    "            non_pad=non_pad.unsqueeze(-1)\n",
    "            temp_tag=torch.cat([torch.tensor(range(num_tags)).view(1, -1, 1) for _ in range(batch_size)], dim=0).to(device)\n",
    "            append_tag = non_pad * temp_tag + (1 - non_pad) * torch.ones(batch_size, num_tags, 1).to(device) * self.pad_id\n",
    "\n",
    "            new_tag=new_tag.long()\n",
    "            pre_tag=tags[[ [i]*num_tags for i in range(batch_size)],new_tag[:,:,0],:]\n",
    "\n",
    "            tags = torch.cat([pre_tag, append_tag], dim=-1)\n",
    "\n",
    "        prob = total_prob + self.transition[:, self.end_id].unsqueeze(0)\n",
    "        _, max_tag = torch.max(prob, dim=1)\n",
    "\n",
    "        return tags[[ i for i in range(batch_size)], max_tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "def NN_embdding(model, train, test, learning_rate, iter_times,batch_size):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_loss_record = list()\n",
    "    test_loss_record = list()\n",
    "    train_record = list()\n",
    "    test_record = list()\n",
    "    # torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "    for iteration in range(iter_times):\n",
    "        model.train()\n",
    "        for i, batch in enumerate(train):\n",
    "            x, y = batch\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            mask = (y != 0).to(device)\n",
    "            loss = model(x, y, mask).to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        train_acc = list()\n",
    "        test_acc = list()\n",
    "        train_loss = 0\n",
    "        test_loss = 0\n",
    "        for i, batch in enumerate(train):\n",
    "            x, y = batch\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            mask = (y != 0).to(device)\n",
    "            loss = model(x, y, mask).to(device)\n",
    "            train_loss += loss.item() / batch_size / y.shape[1]\n",
    "            pred = model.predict(x, mask)\n",
    "            acc = (pred == y).float()\n",
    "            len_batch,len_seq=acc.shape\n",
    "            points=torch.ones((1,len_batch)).to(device)\n",
    "            for j in range(len_seq):\n",
    "                points*=acc[:,j]\n",
    "            train_acc.append(points.mean())\n",
    "\n",
    "        for i, batch in enumerate(test):\n",
    "            x, y = batch\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            mask = (y != 0).to(device)\n",
    "            loss = model(x, y, mask).to(device)\n",
    "            test_loss += loss.item() / batch_size / y.shape[1]\n",
    "            pred = model.predict(x, mask)\n",
    "            acc = (pred == y).float()\n",
    "            len_batch,len_seq=acc.shape\n",
    "            points=torch.ones((1,len_batch)).to(device)\n",
    "            for j in range(len_seq):\n",
    "                points*=acc[:,j]\n",
    "            test_acc.append(points.mean())\n",
    "\n",
    "        trains_acc = sum(train_acc) / len(train_acc)\n",
    "        tests_acc = sum(test_acc) / len(test_acc)\n",
    "\n",
    "        train_loss_record.append(train_loss / len(train))\n",
    "        test_loss_record.append(test_loss / len(test))\n",
    "        train_record.append(trains_acc)\n",
    "        test_record.append(tests_acc)\n",
    "        print(\"---------- Iteration\", iteration + 1, \"----------\")\n",
    "        print(\"Train loss:\", train_loss / len(train))\n",
    "        print(\"Test loss:\", test_loss / len(test))\n",
    "        print(\"Train accuracy:\", trains_acc)\n",
    "        print(\"Test accuracy:\", tests_acc)\n",
    "\n",
    "    return train_loss_record, test_loss_record, train_record, test_record\n",
    "\n",
    "\n",
    "def NN_plot(random_embedding, glove_embedding, len_feature, len_hidden, learning_rate, batch_size, iter_times):\n",
    "    train_random = get_batch(random_embedding.train_x_matrix, random_embedding.train_y_matrix, batch_size)\n",
    "    test_random = get_batch(random_embedding.test_x_matrix, random_embedding.test_y_matrix, batch_size)\n",
    "    train_glove = get_batch(glove_embedding.train_x_matrix, glove_embedding.train_y_matrix, batch_size)\n",
    "    test_glove = get_batch(glove_embedding.test_x_matrix, glove_embedding.test_y_matrix, batch_size)\n",
    "    random_model = Named_Entity_Recognition(len_feature, random_embedding.len_words, len_hidden,\n",
    "                                            random_embedding.len_tag, 0, 1, 2)\n",
    "    glove_model = Named_Entity_Recognition(len_feature, random_embedding.len_words, len_hidden,\n",
    "                                           random_embedding.len_tag, 0, 1, 2,\n",
    "                                           weight=torch.tensor(glove_embedding.embedding, dtype=torch.float))\n",
    "    trl_ran, tsl_ran, tra_ran, tea_ran = NN_embdding(random_model, train_random, test_random, learning_rate,\n",
    "                                                     iter_times,batch_size)\n",
    "    trl_glo, tsl_glo, tra_glo, tea_glo = NN_embdding(glove_model, train_glove, test_glove, learning_rate,\n",
    "                                                     iter_times,batch_size)\n",
    "    x = list(range(1, iter_times + 1))\n",
    "    matplotlib.pyplot.subplot(2, 2, 1)\n",
    "    matplotlib.pyplot.plot(x, trl_ran, 'r--', label='random')\n",
    "    matplotlib.pyplot.plot(x, trl_glo, 'g--', label='glove')\n",
    "    matplotlib.pyplot.legend(fontsize=10)\n",
    "    matplotlib.pyplot.title(\"Train Loss\")\n",
    "    matplotlib.pyplot.xlabel(\"Iterations\")\n",
    "    matplotlib.pyplot.ylabel(\"Loss\")\n",
    "    matplotlib.pyplot.subplot(2, 2, 2)\n",
    "    matplotlib.pyplot.plot(x, tsl_ran, 'r--', label='random')\n",
    "    matplotlib.pyplot.plot(x, tsl_glo, 'g--', label='glove')\n",
    "    matplotlib.pyplot.legend(fontsize=10)\n",
    "    matplotlib.pyplot.title(\"Test Loss\")\n",
    "    matplotlib.pyplot.xlabel(\"Iterations\")\n",
    "    matplotlib.pyplot.ylabel(\"Loss\")\n",
    "    matplotlib.pyplot.subplot(2, 2, 3)\n",
    "    matplotlib.pyplot.plot(x, tra_ran, 'r--', label='random')\n",
    "    matplotlib.pyplot.plot(x, tra_glo, 'g--', label='glove')\n",
    "    matplotlib.pyplot.legend(fontsize=10)\n",
    "    matplotlib.pyplot.title(\"Train Accuracy\")\n",
    "    matplotlib.pyplot.xlabel(\"Iterations\")\n",
    "    matplotlib.pyplot.ylabel(\"Accuracy\")\n",
    "    matplotlib.pyplot.ylim(0, 1)\n",
    "    matplotlib.pyplot.subplot(2, 2, 4)\n",
    "    matplotlib.pyplot.plot(x, tea_ran, 'r--', label='random')\n",
    "    matplotlib.pyplot.plot(x, tea_glo, 'g--', label='glove')\n",
    "    matplotlib.pyplot.legend(fontsize=10)\n",
    "    matplotlib.pyplot.title(\"Test Accuracy\")\n",
    "    matplotlib.pyplot.xlabel(\"Iterations\")\n",
    "    matplotlib.pyplot.ylabel(\"Accuracy\")\n",
    "    matplotlib.pyplot.ylim(0, 1)\n",
    "    matplotlib.pyplot.tight_layout()\n",
    "    fig = matplotlib.pyplot.gcf()\n",
    "    fig.set_size_inches(8, 8, forward=True)\n",
    "    matplotlib.pyplot.savefig('main_plot.jpg')\n",
    "    matplotlib.pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Iteration 1 ----------\n",
      "Train loss: 0.7254413833602202\n",
      "Test loss: 0.7523309149715205\n",
      "Train accuracy: tensor(0.2250)\n",
      "Test accuracy: tensor(0.2224)\n",
      "---------- Iteration 2 ----------\n",
      "Train loss: 0.45925176729456185\n",
      "Test loss: 0.5460758869688626\n",
      "Train accuracy: tensor(0.3704)\n",
      "Test accuracy: tensor(0.2853)\n",
      "---------- Iteration 3 ----------\n",
      "Train loss: 0.3434760800979242\n",
      "Test loss: 0.47130923185322376\n",
      "Train accuracy: tensor(0.4246)\n",
      "Test accuracy: tensor(0.3247)\n",
      "---------- Iteration 4 ----------\n",
      "Train loss: 0.2740436473479306\n",
      "Test loss: 0.42580604018988827\n",
      "Train accuracy: tensor(0.5383)\n",
      "Test accuracy: tensor(0.4368)\n",
      "---------- Iteration 5 ----------\n",
      "Train loss: 0.22321551963675876\n",
      "Test loss: 0.3963778612453987\n",
      "Train accuracy: tensor(0.6396)\n",
      "Test accuracy: tensor(0.4700)\n",
      "---------- Iteration 6 ----------\n",
      "Train loss: 0.165920467188776\n",
      "Test loss: 0.36430680192832715\n",
      "Train accuracy: tensor(0.7539)\n",
      "Test accuracy: tensor(0.4712)\n",
      "---------- Iteration 7 ----------\n",
      "Train loss: 0.11599711125401489\n",
      "Test loss: 0.3448195283076427\n",
      "Train accuracy: tensor(0.8208)\n",
      "Test accuracy: tensor(0.4944)\n",
      "---------- Iteration 8 ----------\n",
      "Train loss: 0.08526814135299388\n",
      "Test loss: 0.334523818777984\n",
      "Train accuracy: tensor(0.8539)\n",
      "Test accuracy: tensor(0.5012)\n",
      "---------- Iteration 9 ----------\n",
      "Train loss: 0.06592492842016362\n",
      "Test loss: 0.32952445420356347\n",
      "Train accuracy: tensor(0.8779)\n",
      "Test accuracy: tensor(0.5097)\n",
      "---------- Iteration 10 ----------\n",
      "Train loss: 0.05304421845524515\n",
      "Test loss: 0.3273592684923466\n",
      "Train accuracy: tensor(0.8980)\n",
      "Test accuracy: tensor(0.5218)\n",
      "---------- Iteration 11 ----------\n",
      "Train loss: 0.04245772041956601\n",
      "Test loss: 0.32745451733904873\n",
      "Train accuracy: tensor(0.9156)\n",
      "Test accuracy: tensor(0.5332)\n",
      "---------- Iteration 12 ----------\n",
      "Train loss: 0.03484506506280968\n",
      "Test loss: 0.32868079585801935\n",
      "Train accuracy: tensor(0.9313)\n",
      "Test accuracy: tensor(0.5368)\n",
      "---------- Iteration 13 ----------\n",
      "Train loss: 0.030164127314228826\n",
      "Test loss: 0.3185555333556249\n",
      "Train accuracy: tensor(0.9368)\n",
      "Test accuracy: tensor(0.5494)\n",
      "---------- Iteration 14 ----------\n",
      "Train loss: 0.025174365953509678\n",
      "Test loss: 0.3225862224709505\n",
      "Train accuracy: tensor(0.9491)\n",
      "Test accuracy: tensor(0.5438)\n",
      "---------- Iteration 15 ----------\n",
      "Train loss: 0.022260992125679255\n",
      "Test loss: 0.3207271236113773\n",
      "Train accuracy: tensor(0.9534)\n",
      "Test accuracy: tensor(0.5497)\n",
      "---------- Iteration 16 ----------\n",
      "Train loss: 0.020899347784833773\n",
      "Test loss: 0.320012562752862\n",
      "Train accuracy: tensor(0.9551)\n",
      "Test accuracy: tensor(0.5497)\n",
      "---------- Iteration 17 ----------\n",
      "Train loss: 0.017619294517881585\n",
      "Test loss: 0.3260650889272149\n",
      "Train accuracy: tensor(0.9626)\n",
      "Test accuracy: tensor(0.5594)\n",
      "---------- Iteration 18 ----------\n",
      "Train loss: 0.015424610809283376\n",
      "Test loss: 0.33107579005179444\n",
      "Train accuracy: tensor(0.9706)\n",
      "Test accuracy: tensor(0.5556)\n",
      "---------- Iteration 19 ----------\n",
      "Train loss: 0.013593952580357777\n",
      "Test loss: 0.34580360099857793\n",
      "Train accuracy: tensor(0.9742)\n",
      "Test accuracy: tensor(0.5459)\n",
      "---------- Iteration 20 ----------\n",
      "Train loss: 0.01354565707251027\n",
      "Test loss: 0.35300408094405455\n",
      "Train accuracy: tensor(0.9705)\n",
      "Test accuracy: tensor(0.5406)\n",
      "---------- Iteration 21 ----------\n",
      "Train loss: 0.012431809913562958\n",
      "Test loss: 0.3261666364665075\n",
      "Train accuracy: tensor(0.9773)\n",
      "Test accuracy: tensor(0.5632)\n",
      "---------- Iteration 22 ----------\n",
      "Train loss: 0.010530364761910339\n",
      "Test loss: 0.34264020119669936\n",
      "Train accuracy: tensor(0.9801)\n",
      "Test accuracy: tensor(0.5574)\n",
      "---------- Iteration 23 ----------\n",
      "Train loss: 0.00993332354986437\n",
      "Test loss: 0.33375291981522187\n",
      "Train accuracy: tensor(0.9809)\n",
      "Test accuracy: tensor(0.5632)\n",
      "---------- Iteration 24 ----------\n",
      "Train loss: 0.009045188938828202\n",
      "Test loss: 0.3433620200989105\n",
      "Train accuracy: tensor(0.9827)\n",
      "Test accuracy: tensor(0.5562)\n",
      "---------- Iteration 25 ----------\n",
      "Train loss: 0.008468088919173403\n",
      "Test loss: 0.3368696455660909\n",
      "Train accuracy: tensor(0.9841)\n",
      "Test accuracy: tensor(0.5682)\n",
      "---------- Iteration 26 ----------\n",
      "Train loss: 0.007508022047096652\n",
      "Test loss: 0.35501617147076603\n",
      "Train accuracy: tensor(0.9866)\n",
      "Test accuracy: tensor(0.5529)\n",
      "---------- Iteration 27 ----------\n",
      "Train loss: 0.006932521508855889\n",
      "Test loss: 0.3492703454526052\n",
      "Train accuracy: tensor(0.9866)\n",
      "Test accuracy: tensor(0.5606)\n",
      "---------- Iteration 28 ----------\n",
      "Train loss: 0.007173767081849138\n",
      "Test loss: 0.3503485264678117\n",
      "Train accuracy: tensor(0.9873)\n",
      "Test accuracy: tensor(0.5674)\n",
      "---------- Iteration 29 ----------\n",
      "Train loss: 0.006772036353723435\n",
      "Test loss: 0.35068173994318164\n",
      "Train accuracy: tensor(0.9871)\n",
      "Test accuracy: tensor(0.5641)\n",
      "---------- Iteration 30 ----------\n",
      "Train loss: 0.007419165687444139\n",
      "Test loss: 0.3576337894175871\n",
      "Train accuracy: tensor(0.9839)\n",
      "Test accuracy: tensor(0.5762)\n",
      "---------- Iteration 31 ----------\n",
      "Train loss: 0.008208717946140224\n",
      "Test loss: 0.37546966327785236\n",
      "Train accuracy: tensor(0.9775)\n",
      "Test accuracy: tensor(0.5674)\n",
      "---------- Iteration 32 ----------\n",
      "Train loss: 0.005504786577638486\n",
      "Test loss: 0.37452923640129515\n",
      "Train accuracy: tensor(0.9889)\n",
      "Test accuracy: tensor(0.5656)\n",
      "---------- Iteration 33 ----------\n",
      "Train loss: 0.005451668385358644\n",
      "Test loss: 0.36873120464126624\n",
      "Train accuracy: tensor(0.9884)\n",
      "Test accuracy: tensor(0.5685)\n",
      "---------- Iteration 34 ----------\n",
      "Train loss: 0.004610735563916408\n",
      "Test loss: 0.3805193286005202\n",
      "Train accuracy: tensor(0.9924)\n",
      "Test accuracy: tensor(0.5547)\n",
      "---------- Iteration 35 ----------\n",
      "Train loss: 0.004463230025324664\n",
      "Test loss: 0.3873785099222318\n",
      "Train accuracy: tensor(0.9906)\n",
      "Test accuracy: tensor(0.5653)\n",
      "---------- Iteration 36 ----------\n",
      "Train loss: 0.004424321842265993\n",
      "Test loss: 0.3848951670316322\n",
      "Train accuracy: tensor(0.9906)\n",
      "Test accuracy: tensor(0.5659)\n",
      "---------- Iteration 37 ----------\n",
      "Train loss: 0.0042895142597290685\n",
      "Test loss: 0.3957842330231063\n",
      "Train accuracy: tensor(0.9926)\n",
      "Test accuracy: tensor(0.5456)\n",
      "---------- Iteration 38 ----------\n",
      "Train loss: 0.003877674278331707\n",
      "Test loss: 0.3843642964481126\n",
      "Train accuracy: tensor(0.9929)\n",
      "Test accuracy: tensor(0.5668)\n",
      "---------- Iteration 39 ----------\n",
      "Train loss: 0.003556883826142298\n",
      "Test loss: 0.3931461937099233\n",
      "Train accuracy: tensor(0.9939)\n",
      "Test accuracy: tensor(0.5647)\n",
      "---------- Iteration 40 ----------\n",
      "Train loss: 0.0035220357348021516\n",
      "Test loss: 0.40218636394072305\n",
      "Train accuracy: tensor(0.9939)\n",
      "Test accuracy: tensor(0.5565)\n",
      "---------- Iteration 41 ----------\n",
      "Train loss: 0.0035583900907807907\n",
      "Test loss: 0.40311644599190183\n",
      "Train accuracy: tensor(0.9936)\n",
      "Test accuracy: tensor(0.5538)\n",
      "---------- Iteration 42 ----------\n",
      "Train loss: 0.0034444884995062023\n",
      "Test loss: 0.4103048672439349\n",
      "Train accuracy: tensor(0.9928)\n",
      "Test accuracy: tensor(0.5497)\n",
      "---------- Iteration 43 ----------\n",
      "Train loss: 0.003212826644849545\n",
      "Test loss: 0.40288563668353405\n",
      "Train accuracy: tensor(0.9937)\n",
      "Test accuracy: tensor(0.5518)\n",
      "---------- Iteration 44 ----------\n",
      "Train loss: 0.003088239650251269\n",
      "Test loss: 0.4021377210483862\n",
      "Train accuracy: tensor(0.9939)\n",
      "Test accuracy: tensor(0.5609)\n",
      "---------- Iteration 45 ----------\n",
      "Train loss: 0.0028687447493546607\n",
      "Test loss: 0.4146282353445645\n",
      "Train accuracy: tensor(0.9948)\n",
      "Test accuracy: tensor(0.5462)\n",
      "---------- Iteration 46 ----------\n",
      "Train loss: 0.0031680249741229474\n",
      "Test loss: 0.4028311593374522\n",
      "Train accuracy: tensor(0.9939)\n",
      "Test accuracy: tensor(0.5488)\n",
      "---------- Iteration 47 ----------\n",
      "Train loss: 0.0027468310393392948\n",
      "Test loss: 0.4133465803068067\n",
      "Train accuracy: tensor(0.9948)\n",
      "Test accuracy: tensor(0.5424)\n",
      "---------- Iteration 48 ----------\n",
      "Train loss: 0.0024466067511139016\n",
      "Test loss: 0.39028696735758317\n",
      "Train accuracy: tensor(0.9957)\n",
      "Test accuracy: tensor(0.5668)\n",
      "---------- Iteration 49 ----------\n",
      "Train loss: 0.002423551233174547\n",
      "Test loss: 0.3979101157101367\n",
      "Train accuracy: tensor(0.9951)\n",
      "Test accuracy: tensor(0.5712)\n",
      "---------- Iteration 50 ----------\n",
      "Train loss: 0.0022507843656775417\n",
      "Test loss: 0.39898896972617637\n",
      "Train accuracy: tensor(0.9963)\n",
      "Test accuracy: tensor(0.5744)\n",
      "---------- Iteration 51 ----------\n",
      "Train loss: 0.0020829233638924955\n",
      "Test loss: 0.41538925970538054\n",
      "Train accuracy: tensor(0.9964)\n",
      "Test accuracy: tensor(0.5638)\n",
      "---------- Iteration 52 ----------\n",
      "Train loss: 0.0021061999769372243\n",
      "Test loss: 0.41438508557927484\n",
      "Train accuracy: tensor(0.9964)\n",
      "Test accuracy: tensor(0.5641)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Iteration 53 ----------\n",
      "Train loss: 0.0018298123296916352\n",
      "Test loss: 0.4152719872872651\n",
      "Train accuracy: tensor(0.9965)\n",
      "Test accuracy: tensor(0.5571)\n",
      "---------- Iteration 54 ----------\n",
      "Train loss: 0.0019059062442317095\n",
      "Test loss: 0.4112051661590706\n",
      "Train accuracy: tensor(0.9959)\n",
      "Test accuracy: tensor(0.5600)\n",
      "---------- Iteration 55 ----------\n",
      "Train loss: 0.0017253461672290173\n",
      "Test loss: 0.421288019756086\n",
      "Train accuracy: tensor(0.9969)\n",
      "Test accuracy: tensor(0.5597)\n",
      "---------- Iteration 56 ----------\n",
      "Train loss: 0.0019233549538241583\n",
      "Test loss: 0.41339170001459413\n",
      "Train accuracy: tensor(0.9970)\n",
      "Test accuracy: tensor(0.5709)\n",
      "---------- Iteration 57 ----------\n",
      "Train loss: 0.0018326223907703914\n",
      "Test loss: 0.4069268147001265\n",
      "Train accuracy: tensor(0.9969)\n",
      "Test accuracy: tensor(0.5768)\n",
      "---------- Iteration 58 ----------\n",
      "Train loss: 0.0015270483239343705\n",
      "Test loss: 0.42554523350578505\n",
      "Train accuracy: tensor(0.9973)\n",
      "Test accuracy: tensor(0.5626)\n",
      "---------- Iteration 59 ----------\n",
      "Train loss: 0.0017600187983666286\n",
      "Test loss: 0.4102561520857308\n",
      "Train accuracy: tensor(0.9966)\n",
      "Test accuracy: tensor(0.5744)\n",
      "---------- Iteration 60 ----------\n",
      "Train loss: 0.0018557090916914327\n",
      "Test loss: 0.40235277971775996\n",
      "Train accuracy: tensor(0.9964)\n",
      "Test accuracy: tensor(0.5812)\n",
      "---------- Iteration 61 ----------\n",
      "Train loss: 0.00206608530175128\n",
      "Test loss: 0.42127957927367854\n",
      "Train accuracy: tensor(0.9959)\n",
      "Test accuracy: tensor(0.5735)\n",
      "---------- Iteration 62 ----------\n",
      "Train loss: 0.0016249025350810542\n",
      "Test loss: 0.44088385706188915\n",
      "Train accuracy: tensor(0.9965)\n",
      "Test accuracy: tensor(0.5694)\n",
      "---------- Iteration 63 ----------\n",
      "Train loss: 0.0014837993328253734\n",
      "Test loss: 0.41116226944731277\n",
      "Train accuracy: tensor(0.9973)\n",
      "Test accuracy: tensor(0.5744)\n",
      "---------- Iteration 64 ----------\n",
      "Train loss: 0.0012252603349816303\n",
      "Test loss: 0.4204427931607346\n",
      "Train accuracy: tensor(0.9981)\n",
      "Test accuracy: tensor(0.5859)\n",
      "---------- Iteration 65 ----------\n",
      "Train loss: 0.0012382811490081714\n",
      "Test loss: 0.43281761585601997\n",
      "Train accuracy: tensor(0.9981)\n",
      "Test accuracy: tensor(0.5662)\n",
      "---------- Iteration 66 ----------\n",
      "Train loss: 0.001235114444220324\n",
      "Test loss: 0.43304996139517177\n",
      "Train accuracy: tensor(0.9979)\n",
      "Test accuracy: tensor(0.5668)\n",
      "---------- Iteration 67 ----------\n",
      "Train loss: 0.0014923968060461545\n",
      "Test loss: 0.43132015830825515\n",
      "Train accuracy: tensor(0.9971)\n",
      "Test accuracy: tensor(0.5753)\n",
      "---------- Iteration 68 ----------\n",
      "Train loss: 0.0012145084616418905\n",
      "Test loss: 0.44130006838448876\n",
      "Train accuracy: tensor(0.9980)\n",
      "Test accuracy: tensor(0.5688)\n",
      "---------- Iteration 69 ----------\n",
      "Train loss: 0.001232210471204818\n",
      "Test loss: 0.43432036490112175\n",
      "Train accuracy: tensor(0.9977)\n",
      "Test accuracy: tensor(0.5732)\n",
      "---------- Iteration 70 ----------\n",
      "Train loss: 0.0012643112111024443\n",
      "Test loss: 0.44275183613805613\n",
      "Train accuracy: tensor(0.9976)\n",
      "Test accuracy: tensor(0.5647)\n",
      "---------- Iteration 71 ----------\n",
      "Train loss: 0.0010556369421160037\n",
      "Test loss: 0.4352379727896804\n",
      "Train accuracy: tensor(0.9981)\n",
      "Test accuracy: tensor(0.5674)\n",
      "---------- Iteration 72 ----------\n",
      "Train loss: 0.0010768722328780291\n",
      "Test loss: 0.41666773959828163\n",
      "Train accuracy: tensor(0.9984)\n",
      "Test accuracy: tensor(0.5797)\n",
      "---------- Iteration 73 ----------\n",
      "Train loss: 0.0010741539461553123\n",
      "Test loss: 0.44700647417585604\n",
      "Train accuracy: tensor(0.9985)\n",
      "Test accuracy: tensor(0.5638)\n",
      "---------- Iteration 74 ----------\n",
      "Train loss: 0.0010912469209733552\n",
      "Test loss: 0.438479222798279\n",
      "Train accuracy: tensor(0.9986)\n",
      "Test accuracy: tensor(0.5679)\n",
      "---------- Iteration 75 ----------\n",
      "Train loss: 0.0012174375450989608\n",
      "Test loss: 0.4379521748427741\n",
      "Train accuracy: tensor(0.9979)\n",
      "Test accuracy: tensor(0.5785)\n",
      "---------- Iteration 76 ----------\n",
      "Train loss: 0.0009675078517284824\n",
      "Test loss: 0.4483065537275422\n",
      "Train accuracy: tensor(0.9981)\n",
      "Test accuracy: tensor(0.5644)\n",
      "---------- Iteration 77 ----------\n",
      "Train loss: 0.001072484083106451\n",
      "Test loss: 0.45483737943454305\n",
      "Train accuracy: tensor(0.9979)\n",
      "Test accuracy: tensor(0.5635)\n",
      "---------- Iteration 78 ----------\n",
      "Train loss: 0.0008834980480257597\n",
      "Test loss: 0.46534556457335\n",
      "Train accuracy: tensor(0.9986)\n",
      "Test accuracy: tensor(0.5621)\n",
      "---------- Iteration 79 ----------\n",
      "Train loss: 0.0008385391581709317\n",
      "Test loss: 0.4480962456594685\n",
      "Train accuracy: tensor(0.9986)\n",
      "Test accuracy: tensor(0.5706)\n",
      "---------- Iteration 80 ----------\n",
      "Train loss: 0.000786930083712361\n",
      "Test loss: 0.4437607800370791\n",
      "Train accuracy: tensor(0.9982)\n",
      "Test accuracy: tensor(0.5726)\n",
      "---------- Iteration 81 ----------\n",
      "Train loss: 0.0009527874629444155\n",
      "Test loss: 0.44863322733277355\n",
      "Train accuracy: tensor(0.9983)\n",
      "Test accuracy: tensor(0.5753)\n",
      "---------- Iteration 82 ----------\n",
      "Train loss: 0.0009667419343140185\n",
      "Test loss: 0.4531963762797717\n",
      "Train accuracy: tensor(0.9980)\n",
      "Test accuracy: tensor(0.5738)\n",
      "---------- Iteration 83 ----------\n",
      "Train loss: 0.0006710791782169553\n",
      "Test loss: 0.44458226532997486\n",
      "Train accuracy: tensor(0.9986)\n",
      "Test accuracy: tensor(0.5829)\n",
      "---------- Iteration 84 ----------\n",
      "Train loss: 0.0007367888231421131\n",
      "Test loss: 0.462915545330259\n",
      "Train accuracy: tensor(0.9987)\n",
      "Test accuracy: tensor(0.5732)\n",
      "---------- Iteration 85 ----------\n",
      "Train loss: 0.0006946167906676838\n",
      "Test loss: 0.4704181323445688\n",
      "Train accuracy: tensor(0.9986)\n",
      "Test accuracy: tensor(0.5738)\n",
      "---------- Iteration 86 ----------\n",
      "Train loss: 0.0008052506618852516\n",
      "Test loss: 0.44741006778848386\n",
      "Train accuracy: tensor(0.9984)\n",
      "Test accuracy: tensor(0.5744)\n",
      "---------- Iteration 87 ----------\n",
      "Train loss: 0.0008723998541867249\n",
      "Test loss: 0.44466253719966614\n",
      "Train accuracy: tensor(0.9981)\n",
      "Test accuracy: tensor(0.5985)\n",
      "---------- Iteration 88 ----------\n",
      "Train loss: 0.0007552177791583364\n",
      "Test loss: 0.4353931933800076\n",
      "Train accuracy: tensor(0.9983)\n",
      "Test accuracy: tensor(0.5938)\n",
      "---------- Iteration 89 ----------\n",
      "Train loss: 0.0007603694982466215\n",
      "Test loss: 0.4678589598168634\n",
      "Train accuracy: tensor(0.9985)\n",
      "Test accuracy: tensor(0.5738)\n",
      "---------- Iteration 90 ----------\n",
      "Train loss: 0.0006977164113880616\n",
      "Test loss: 0.4580221576985566\n",
      "Train accuracy: tensor(0.9987)\n",
      "Test accuracy: tensor(0.5765)\n",
      "---------- Iteration 91 ----------\n",
      "Train loss: 0.0006436238736649288\n",
      "Test loss: 0.4577089995043509\n",
      "Train accuracy: tensor(0.9986)\n",
      "Test accuracy: tensor(0.5724)\n",
      "---------- Iteration 92 ----------\n",
      "Train loss: 0.0007158040198607465\n",
      "Test loss: 0.4517006104860238\n",
      "Train accuracy: tensor(0.9986)\n",
      "Test accuracy: tensor(0.5776)\n",
      "---------- Iteration 93 ----------\n",
      "Train loss: 0.0006770408077132825\n",
      "Test loss: 0.47472211280854604\n",
      "Train accuracy: tensor(0.9985)\n",
      "Test accuracy: tensor(0.5729)\n",
      "---------- Iteration 94 ----------\n",
      "Train loss: 0.000602070796047151\n",
      "Test loss: 0.46382590632322\n",
      "Train accuracy: tensor(0.9987)\n",
      "Test accuracy: tensor(0.5871)\n",
      "---------- Iteration 95 ----------\n",
      "Train loss: 0.0006008143662801501\n",
      "Test loss: 0.47120138331624495\n",
      "Train accuracy: tensor(0.9986)\n",
      "Test accuracy: tensor(0.5718)\n",
      "---------- Iteration 96 ----------\n",
      "Train loss: 0.0005334909740345461\n",
      "Test loss: 0.4789392905808422\n",
      "Train accuracy: tensor(0.9990)\n",
      "Test accuracy: tensor(0.5738)\n",
      "---------- Iteration 97 ----------\n",
      "Train loss: 0.0005629058030338552\n",
      "Test loss: 0.4511137670434539\n",
      "Train accuracy: tensor(0.9990)\n",
      "Test accuracy: tensor(0.5718)\n",
      "---------- Iteration 98 ----------\n",
      "Train loss: 0.0005278973409284066\n",
      "Test loss: 0.4779548961126631\n",
      "Train accuracy: tensor(0.9988)\n",
      "Test accuracy: tensor(0.5697)\n",
      "---------- Iteration 99 ----------\n",
      "Train loss: 0.0005334740666165376\n",
      "Test loss: 0.46141983330498654\n",
      "Train accuracy: tensor(0.9990)\n",
      "Test accuracy: tensor(0.5753)\n",
      "---------- Iteration 100 ----------\n",
      "Train loss: 0.000567040294539127\n",
      "Test loss: 0.46345267126731554\n",
      "Train accuracy: tensor(0.9989)\n",
      "Test accuracy: tensor(0.5779)\n",
      "---------- Iteration 1 ----------\n",
      "Train loss: 0.5403295923466416\n",
      "Test loss: 0.5273538616207165\n",
      "Train accuracy: tensor(0.3719)\n",
      "Test accuracy: tensor(0.3744)\n",
      "---------- Iteration 2 ----------\n",
      "Train loss: 0.3375898723047525\n",
      "Test loss: 0.3437797502836864\n",
      "Train accuracy: tensor(0.5118)\n",
      "Test accuracy: tensor(0.5206)\n",
      "---------- Iteration 3 ----------\n",
      "Train loss: 0.24007229682027445\n",
      "Test loss: 0.25845257297762025\n",
      "Train accuracy: tensor(0.6126)\n",
      "Test accuracy: tensor(0.6159)\n",
      "---------- Iteration 4 ----------\n",
      "Train loss: 0.1826138815009058\n",
      "Test loss: 0.20969939378537883\n",
      "Train accuracy: tensor(0.6831)\n",
      "Test accuracy: tensor(0.6665)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Iteration 5 ----------\n",
      "Train loss: 0.14794418949328278\n",
      "Test loss: 0.18307045791072976\n",
      "Train accuracy: tensor(0.7219)\n",
      "Test accuracy: tensor(0.6871)\n",
      "---------- Iteration 6 ----------\n",
      "Train loss: 0.1214283410360308\n",
      "Test loss: 0.1644209963678098\n",
      "Train accuracy: tensor(0.7526)\n",
      "Test accuracy: tensor(0.7050)\n",
      "---------- Iteration 7 ----------\n",
      "Train loss: 0.10494337361233676\n",
      "Test loss: 0.1555443816590093\n",
      "Train accuracy: tensor(0.7737)\n",
      "Test accuracy: tensor(0.7129)\n",
      "---------- Iteration 8 ----------\n",
      "Train loss: 0.0911440807874904\n",
      "Test loss: 0.14820574447947066\n",
      "Train accuracy: tensor(0.8005)\n",
      "Test accuracy: tensor(0.7253)\n",
      "---------- Iteration 9 ----------\n",
      "Train loss: 0.08017347430209198\n",
      "Test loss: 0.14312724102089147\n",
      "Train accuracy: tensor(0.8200)\n",
      "Test accuracy: tensor(0.7332)\n",
      "---------- Iteration 10 ----------\n",
      "Train loss: 0.07121927900043269\n",
      "Test loss: 0.14068157008567364\n",
      "Train accuracy: tensor(0.8381)\n",
      "Test accuracy: tensor(0.7394)\n",
      "---------- Iteration 11 ----------\n",
      "Train loss: 0.06382305269932867\n",
      "Test loss: 0.13616537364217074\n",
      "Train accuracy: tensor(0.8484)\n",
      "Test accuracy: tensor(0.7482)\n",
      "---------- Iteration 12 ----------\n",
      "Train loss: 0.0583596726206457\n",
      "Test loss: 0.13399395893853058\n",
      "Train accuracy: tensor(0.8587)\n",
      "Test accuracy: tensor(0.7506)\n",
      "---------- Iteration 13 ----------\n",
      "Train loss: 0.05319563891296009\n",
      "Test loss: 0.1336604068818192\n",
      "Train accuracy: tensor(0.8685)\n",
      "Test accuracy: tensor(0.7526)\n",
      "---------- Iteration 14 ----------\n",
      "Train loss: 0.04858219805931234\n",
      "Test loss: 0.13284608799860584\n",
      "Train accuracy: tensor(0.8744)\n",
      "Test accuracy: tensor(0.7544)\n",
      "---------- Iteration 15 ----------\n",
      "Train loss: 0.04473254214501776\n",
      "Test loss: 0.13250288348518102\n",
      "Train accuracy: tensor(0.8846)\n",
      "Test accuracy: tensor(0.7571)\n",
      "---------- Iteration 16 ----------\n",
      "Train loss: 0.041307851608534694\n",
      "Test loss: 0.13138398183321717\n",
      "Train accuracy: tensor(0.8905)\n",
      "Test accuracy: tensor(0.7647)\n",
      "---------- Iteration 17 ----------\n",
      "Train loss: 0.03833339422748619\n",
      "Test loss: 0.13101514457292626\n",
      "Train accuracy: tensor(0.8967)\n",
      "Test accuracy: tensor(0.7597)\n",
      "---------- Iteration 18 ----------\n",
      "Train loss: 0.035315236292699316\n",
      "Test loss: 0.13034019512867384\n",
      "Train accuracy: tensor(0.9020)\n",
      "Test accuracy: tensor(0.7615)\n",
      "---------- Iteration 19 ----------\n",
      "Train loss: 0.03334703629918319\n",
      "Test loss: 0.12922378264542878\n",
      "Train accuracy: tensor(0.9081)\n",
      "Test accuracy: tensor(0.7632)\n",
      "---------- Iteration 20 ----------\n",
      "Train loss: 0.030958859695190043\n",
      "Test loss: 0.12873100436070978\n",
      "Train accuracy: tensor(0.9127)\n",
      "Test accuracy: tensor(0.7635)\n",
      "---------- Iteration 21 ----------\n",
      "Train loss: 0.02861756306560555\n",
      "Test loss: 0.12954245108056037\n",
      "Train accuracy: tensor(0.9191)\n",
      "Test accuracy: tensor(0.7609)\n",
      "---------- Iteration 22 ----------\n",
      "Train loss: 0.02677407339624531\n",
      "Test loss: 0.13128748154780304\n",
      "Train accuracy: tensor(0.9230)\n",
      "Test accuracy: tensor(0.7624)\n",
      "---------- Iteration 23 ----------\n",
      "Train loss: 0.025073697303241806\n",
      "Test loss: 0.12961386849781042\n",
      "Train accuracy: tensor(0.9272)\n",
      "Test accuracy: tensor(0.7629)\n",
      "---------- Iteration 24 ----------\n",
      "Train loss: 0.023785803294672753\n",
      "Test loss: 0.12946221548194617\n",
      "Train accuracy: tensor(0.9311)\n",
      "Test accuracy: tensor(0.7635)\n",
      "---------- Iteration 25 ----------\n",
      "Train loss: 0.022487973641383083\n",
      "Test loss: 0.13117831180778947\n",
      "Train accuracy: tensor(0.9339)\n",
      "Test accuracy: tensor(0.7656)\n",
      "---------- Iteration 26 ----------\n",
      "Train loss: 0.020978624118892043\n",
      "Test loss: 0.13241008921625025\n",
      "Train accuracy: tensor(0.9371)\n",
      "Test accuracy: tensor(0.7656)\n",
      "---------- Iteration 27 ----------\n",
      "Train loss: 0.019933164937213116\n",
      "Test loss: 0.1325134278159792\n",
      "Train accuracy: tensor(0.9409)\n",
      "Test accuracy: tensor(0.7674)\n",
      "---------- Iteration 28 ----------\n",
      "Train loss: 0.019071730203623558\n",
      "Test loss: 0.13116814796409004\n",
      "Train accuracy: tensor(0.9429)\n",
      "Test accuracy: tensor(0.7691)\n",
      "---------- Iteration 29 ----------\n",
      "Train loss: 0.018042459283894308\n",
      "Test loss: 0.13349809687811853\n",
      "Train accuracy: tensor(0.9441)\n",
      "Test accuracy: tensor(0.7662)\n",
      "---------- Iteration 30 ----------\n",
      "Train loss: 0.01725998669114181\n",
      "Test loss: 0.13370143012238317\n",
      "Train accuracy: tensor(0.9451)\n",
      "Test accuracy: tensor(0.7671)\n",
      "---------- Iteration 31 ----------\n",
      "Train loss: 0.01612239676243953\n",
      "Test loss: 0.13479259855524325\n",
      "Train accuracy: tensor(0.9511)\n",
      "Test accuracy: tensor(0.7662)\n",
      "---------- Iteration 32 ----------\n",
      "Train loss: 0.015457928438032944\n",
      "Test loss: 0.13519291207743522\n",
      "Train accuracy: tensor(0.9529)\n",
      "Test accuracy: tensor(0.7682)\n",
      "---------- Iteration 33 ----------\n",
      "Train loss: 0.01482705474657389\n",
      "Test loss: 0.13451619584524405\n",
      "Train accuracy: tensor(0.9544)\n",
      "Test accuracy: tensor(0.7709)\n",
      "---------- Iteration 34 ----------\n",
      "Train loss: 0.01382047967790841\n",
      "Test loss: 0.1372749128917413\n",
      "Train accuracy: tensor(0.9564)\n",
      "Test accuracy: tensor(0.7653)\n",
      "---------- Iteration 35 ----------\n",
      "Train loss: 0.013330178947633164\n",
      "Test loss: 0.1371928347424511\n",
      "Train accuracy: tensor(0.9580)\n",
      "Test accuracy: tensor(0.7679)\n",
      "---------- Iteration 36 ----------\n",
      "Train loss: 0.012656198481064241\n",
      "Test loss: 0.1369934103706865\n",
      "Train accuracy: tensor(0.9601)\n",
      "Test accuracy: tensor(0.7682)\n",
      "---------- Iteration 37 ----------\n",
      "Train loss: 0.012381167762624242\n",
      "Test loss: 0.1393003472251437\n",
      "Train accuracy: tensor(0.9608)\n",
      "Test accuracy: tensor(0.7653)\n",
      "---------- Iteration 38 ----------\n",
      "Train loss: 0.011655821915636216\n",
      "Test loss: 0.14009316395509483\n",
      "Train accuracy: tensor(0.9619)\n",
      "Test accuracy: tensor(0.7653)\n",
      "---------- Iteration 39 ----------\n",
      "Train loss: 0.011206823280119795\n",
      "Test loss: 0.14247038041572957\n",
      "Train accuracy: tensor(0.9640)\n",
      "Test accuracy: tensor(0.7668)\n",
      "---------- Iteration 40 ----------\n",
      "Train loss: 0.010630678511578147\n",
      "Test loss: 0.14175768613575132\n",
      "Train accuracy: tensor(0.9648)\n",
      "Test accuracy: tensor(0.7685)\n",
      "---------- Iteration 41 ----------\n",
      "Train loss: 0.010308049604987357\n",
      "Test loss: 0.1412107645196693\n",
      "Train accuracy: tensor(0.9658)\n",
      "Test accuracy: tensor(0.7694)\n",
      "---------- Iteration 42 ----------\n",
      "Train loss: 0.009672748202054776\n",
      "Test loss: 0.14259197040447288\n",
      "Train accuracy: tensor(0.9676)\n",
      "Test accuracy: tensor(0.7659)\n",
      "---------- Iteration 43 ----------\n",
      "Train loss: 0.00957921081950816\n",
      "Test loss: 0.1435623310598945\n",
      "Train accuracy: tensor(0.9683)\n",
      "Test accuracy: tensor(0.7700)\n",
      "---------- Iteration 44 ----------\n",
      "Train loss: 0.008922433543934802\n",
      "Test loss: 0.1461271097764014\n",
      "Train accuracy: tensor(0.9694)\n",
      "Test accuracy: tensor(0.7656)\n",
      "---------- Iteration 45 ----------\n",
      "Train loss: 0.008600657041419948\n",
      "Test loss: 0.14473032571451266\n",
      "Train accuracy: tensor(0.9706)\n",
      "Test accuracy: tensor(0.7674)\n",
      "---------- Iteration 46 ----------\n",
      "Train loss: 0.008005133460222922\n",
      "Test loss: 0.14478299474552245\n",
      "Train accuracy: tensor(0.9734)\n",
      "Test accuracy: tensor(0.7682)\n",
      "---------- Iteration 47 ----------\n",
      "Train loss: 0.007711672503703105\n",
      "Test loss: 0.144769808624163\n",
      "Train accuracy: tensor(0.9741)\n",
      "Test accuracy: tensor(0.7709)\n",
      "---------- Iteration 48 ----------\n",
      "Train loss: 0.0074558094394473395\n",
      "Test loss: 0.14924856458473867\n",
      "Train accuracy: tensor(0.9748)\n",
      "Test accuracy: tensor(0.7691)\n",
      "---------- Iteration 49 ----------\n",
      "Train loss: 0.007170754899287046\n",
      "Test loss: 0.15076559687851532\n",
      "Train accuracy: tensor(0.9750)\n",
      "Test accuracy: tensor(0.7712)\n",
      "---------- Iteration 50 ----------\n",
      "Train loss: 0.006941554498415748\n",
      "Test loss: 0.14895060867311155\n",
      "Train accuracy: tensor(0.9772)\n",
      "Test accuracy: tensor(0.7691)\n",
      "---------- Iteration 51 ----------\n",
      "Train loss: 0.0067854862182842035\n",
      "Test loss: 0.15151363100911408\n",
      "Train accuracy: tensor(0.9777)\n",
      "Test accuracy: tensor(0.7718)\n",
      "---------- Iteration 52 ----------\n",
      "Train loss: 0.0063739152523780195\n",
      "Test loss: 0.1509197096217328\n",
      "Train accuracy: tensor(0.9794)\n",
      "Test accuracy: tensor(0.7729)\n",
      "---------- Iteration 53 ----------\n",
      "Train loss: 0.006156166809809974\n",
      "Test loss: 0.15278825896677264\n",
      "Train accuracy: tensor(0.9799)\n",
      "Test accuracy: tensor(0.7700)\n",
      "---------- Iteration 54 ----------\n",
      "Train loss: 0.0060349171143944755\n",
      "Test loss: 0.15122606141907932\n",
      "Train accuracy: tensor(0.9804)\n",
      "Test accuracy: tensor(0.7732)\n",
      "---------- Iteration 55 ----------\n",
      "Train loss: 0.005954976137513763\n",
      "Test loss: 0.15331369642383966\n",
      "Train accuracy: tensor(0.9804)\n",
      "Test accuracy: tensor(0.7688)\n",
      "---------- Iteration 56 ----------\n",
      "Train loss: 0.005691357857618022\n",
      "Test loss: 0.1537439268289979\n",
      "Train accuracy: tensor(0.9809)\n",
      "Test accuracy: tensor(0.7700)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Iteration 57 ----------\n",
      "Train loss: 0.005477565676360884\n",
      "Test loss: 0.15397048680906397\n",
      "Train accuracy: tensor(0.9834)\n",
      "Test accuracy: tensor(0.7712)\n",
      "---------- Iteration 58 ----------\n",
      "Train loss: 0.005150522709100378\n",
      "Test loss: 0.1560502768473421\n",
      "Train accuracy: tensor(0.9832)\n",
      "Test accuracy: tensor(0.7679)\n",
      "---------- Iteration 59 ----------\n",
      "Train loss: 0.004909892972399885\n",
      "Test loss: 0.15588199291978597\n",
      "Train accuracy: tensor(0.9851)\n",
      "Test accuracy: tensor(0.7656)\n",
      "---------- Iteration 60 ----------\n",
      "Train loss: 0.00483124284786199\n",
      "Test loss: 0.1562330424091385\n",
      "Train accuracy: tensor(0.9838)\n",
      "Test accuracy: tensor(0.7679)\n",
      "---------- Iteration 61 ----------\n",
      "Train loss: 0.004673110007945099\n",
      "Test loss: 0.15629193730426275\n",
      "Train accuracy: tensor(0.9846)\n",
      "Test accuracy: tensor(0.7706)\n",
      "---------- Iteration 62 ----------\n",
      "Train loss: 0.00449600881149354\n",
      "Test loss: 0.15872472823989256\n",
      "Train accuracy: tensor(0.9856)\n",
      "Test accuracy: tensor(0.7697)\n",
      "---------- Iteration 63 ----------\n",
      "Train loss: 0.004317512092718416\n",
      "Test loss: 0.15990593040827905\n",
      "Train accuracy: tensor(0.9864)\n",
      "Test accuracy: tensor(0.7691)\n",
      "---------- Iteration 64 ----------\n",
      "Train loss: 0.004285701146774978\n",
      "Test loss: 0.1592985506442793\n",
      "Train accuracy: tensor(0.9856)\n",
      "Test accuracy: tensor(0.7662)\n",
      "---------- Iteration 65 ----------\n",
      "Train loss: 0.003925066646472384\n",
      "Test loss: 0.16199813668840243\n",
      "Train accuracy: tensor(0.9873)\n",
      "Test accuracy: tensor(0.7656)\n",
      "---------- Iteration 66 ----------\n",
      "Train loss: 0.0038321588694969337\n",
      "Test loss: 0.16423107704631448\n",
      "Train accuracy: tensor(0.9874)\n",
      "Test accuracy: tensor(0.7659)\n",
      "---------- Iteration 67 ----------\n",
      "Train loss: 0.0037679859107838656\n",
      "Test loss: 0.16160057701075695\n",
      "Train accuracy: tensor(0.9878)\n",
      "Test accuracy: tensor(0.7662)\n",
      "---------- Iteration 68 ----------\n",
      "Train loss: 0.0035562943342118108\n",
      "Test loss: 0.16727459032248276\n",
      "Train accuracy: tensor(0.9886)\n",
      "Test accuracy: tensor(0.7671)\n",
      "---------- Iteration 69 ----------\n",
      "Train loss: 0.003479831665738297\n",
      "Test loss: 0.1683146915966475\n",
      "Train accuracy: tensor(0.9886)\n",
      "Test accuracy: tensor(0.7679)\n",
      "---------- Iteration 70 ----------\n",
      "Train loss: 0.0032722418791006997\n",
      "Test loss: 0.16403543746853547\n",
      "Train accuracy: tensor(0.9892)\n",
      "Test accuracy: tensor(0.7632)\n",
      "---------- Iteration 71 ----------\n",
      "Train loss: 0.0033189674037809196\n",
      "Test loss: 0.16546731296301664\n",
      "Train accuracy: tensor(0.9891)\n",
      "Test accuracy: tensor(0.7606)\n",
      "---------- Iteration 72 ----------\n",
      "Train loss: 0.003223374459408968\n",
      "Test loss: 0.16537865359754458\n",
      "Train accuracy: tensor(0.9895)\n",
      "Test accuracy: tensor(0.7618)\n",
      "---------- Iteration 73 ----------\n",
      "Train loss: 0.0031746503634885186\n",
      "Test loss: 0.1682844910742856\n",
      "Train accuracy: tensor(0.9892)\n",
      "Test accuracy: tensor(0.7647)\n",
      "---------- Iteration 74 ----------\n",
      "Train loss: 0.003021457289545735\n",
      "Test loss: 0.16408433580085524\n",
      "Train accuracy: tensor(0.9902)\n",
      "Test accuracy: tensor(0.7676)\n",
      "---------- Iteration 75 ----------\n",
      "Train loss: 0.002767180432389048\n",
      "Test loss: 0.16910512802929986\n",
      "Train accuracy: tensor(0.9911)\n",
      "Test accuracy: tensor(0.7668)\n",
      "---------- Iteration 76 ----------\n",
      "Train loss: 0.0027160986855269587\n",
      "Test loss: 0.16895371245210014\n",
      "Train accuracy: tensor(0.9916)\n",
      "Test accuracy: tensor(0.7624)\n",
      "---------- Iteration 77 ----------\n",
      "Train loss: 0.0027006781794963255\n",
      "Test loss: 0.165246215522109\n",
      "Train accuracy: tensor(0.9915)\n",
      "Test accuracy: tensor(0.7635)\n",
      "---------- Iteration 78 ----------\n",
      "Train loss: 0.0026218561129863196\n",
      "Test loss: 0.17162948800918842\n",
      "Train accuracy: tensor(0.9918)\n",
      "Test accuracy: tensor(0.7635)\n",
      "---------- Iteration 79 ----------\n",
      "Train loss: 0.002472018622984944\n",
      "Test loss: 0.17170133182587502\n",
      "Train accuracy: tensor(0.9933)\n",
      "Test accuracy: tensor(0.7697)\n",
      "---------- Iteration 80 ----------\n",
      "Train loss: 0.0024949635815108722\n",
      "Test loss: 0.17476393444859398\n",
      "Train accuracy: tensor(0.9922)\n",
      "Test accuracy: tensor(0.7626)\n",
      "---------- Iteration 81 ----------\n",
      "Train loss: 0.002296374631204339\n",
      "Test loss: 0.18109990194053385\n",
      "Train accuracy: tensor(0.9939)\n",
      "Test accuracy: tensor(0.7682)\n",
      "---------- Iteration 82 ----------\n",
      "Train loss: 0.002368858653526251\n",
      "Test loss: 0.17313738713425778\n",
      "Train accuracy: tensor(0.9924)\n",
      "Test accuracy: tensor(0.7603)\n",
      "---------- Iteration 83 ----------\n",
      "Train loss: 0.0022515211219228375\n",
      "Test loss: 0.17787091350249423\n",
      "Train accuracy: tensor(0.9939)\n",
      "Test accuracy: tensor(0.7656)\n",
      "---------- Iteration 84 ----------\n",
      "Train loss: 0.0022779952886061816\n",
      "Test loss: 0.17524457937007681\n",
      "Train accuracy: tensor(0.9934)\n",
      "Test accuracy: tensor(0.7659)\n",
      "---------- Iteration 85 ----------\n",
      "Train loss: 0.0022899945519375842\n",
      "Test loss: 0.17580329613015516\n",
      "Train accuracy: tensor(0.9932)\n",
      "Test accuracy: tensor(0.7653)\n",
      "---------- Iteration 86 ----------\n",
      "Train loss: 0.002098226313415671\n",
      "Test loss: 0.1768615442244784\n",
      "Train accuracy: tensor(0.9937)\n",
      "Test accuracy: tensor(0.7612)\n",
      "---------- Iteration 87 ----------\n",
      "Train loss: 0.002238728711987728\n",
      "Test loss: 0.1772009995149566\n",
      "Train accuracy: tensor(0.9924)\n",
      "Test accuracy: tensor(0.7568)\n",
      "---------- Iteration 88 ----------\n",
      "Train loss: 0.0020623357708683876\n",
      "Test loss: 0.17452544642910642\n",
      "Train accuracy: tensor(0.9932)\n",
      "Test accuracy: tensor(0.7656)\n",
      "---------- Iteration 89 ----------\n",
      "Train loss: 0.0019820163926192957\n",
      "Test loss: 0.17728706845330341\n",
      "Train accuracy: tensor(0.9943)\n",
      "Test accuracy: tensor(0.7647)\n",
      "---------- Iteration 90 ----------\n",
      "Train loss: 0.0019080532782647154\n",
      "Test loss: 0.17663958196408508\n",
      "Train accuracy: tensor(0.9942)\n",
      "Test accuracy: tensor(0.7665)\n",
      "---------- Iteration 91 ----------\n",
      "Train loss: 0.0018414690563173738\n",
      "Test loss: 0.17587758457964636\n",
      "Train accuracy: tensor(0.9941)\n",
      "Test accuracy: tensor(0.7650)\n",
      "---------- Iteration 92 ----------\n",
      "Train loss: 0.0017614988181157245\n",
      "Test loss: 0.17869003117402046\n",
      "Train accuracy: tensor(0.9945)\n",
      "Test accuracy: tensor(0.7691)\n",
      "---------- Iteration 93 ----------\n",
      "Train loss: 0.0018204488930862223\n",
      "Test loss: 0.1800465962677736\n",
      "Train accuracy: tensor(0.9941)\n",
      "Test accuracy: tensor(0.7653)\n",
      "---------- Iteration 94 ----------\n",
      "Train loss: 0.0017604600088158466\n",
      "Test loss: 0.18155813294965137\n",
      "Train accuracy: tensor(0.9949)\n",
      "Test accuracy: tensor(0.7656)\n",
      "---------- Iteration 95 ----------\n",
      "Train loss: 0.001614384095186269\n",
      "Test loss: 0.17830729085234762\n",
      "Train accuracy: tensor(0.9957)\n",
      "Test accuracy: tensor(0.7632)\n",
      "---------- Iteration 96 ----------\n",
      "Train loss: 0.0016376897690026043\n",
      "Test loss: 0.17850360896332865\n",
      "Train accuracy: tensor(0.9950)\n",
      "Test accuracy: tensor(0.7674)\n",
      "---------- Iteration 97 ----------\n",
      "Train loss: 0.001620646855688899\n",
      "Test loss: 0.18074191123666652\n",
      "Train accuracy: tensor(0.9952)\n",
      "Test accuracy: tensor(0.7641)\n",
      "---------- Iteration 98 ----------\n",
      "Train loss: 0.0014864775068747322\n",
      "Test loss: 0.18105507227539938\n",
      "Train accuracy: tensor(0.9956)\n",
      "Test accuracy: tensor(0.7650)\n",
      "---------- Iteration 99 ----------\n",
      "Train loss: 0.0015265897122591129\n",
      "Test loss: 0.18042078412268742\n",
      "Train accuracy: tensor(0.9958)\n",
      "Test accuracy: tensor(0.7647)\n",
      "---------- Iteration 100 ----------\n",
      "Train loss: 0.0015491997008775231\n",
      "Test loss: 0.18474589304392405\n",
      "Train accuracy: tensor(0.9960)\n",
      "Test accuracy: tensor(0.7659)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load main.py\n",
    "from torch import optim\n",
    "import random,numpy,torch\n",
    "\n",
    "random.seed(2021)\n",
    "numpy.random.seed(2021)\n",
    "#torch.cuda.manual_seed(2021)\n",
    "torch.manual_seed(2021)\n",
    "\n",
    "with open('train.txt', 'r') as f:\n",
    "    temp = f.readlines()\n",
    "\n",
    "data = temp[2:]\n",
    "train_zip = pre_process(data)\n",
    "\n",
    "with open('test.txt', 'r') as f:\n",
    "    temp = f.readlines()\n",
    "\n",
    "data = temp[2:]\n",
    "test_zip = pre_process(data)\n",
    "\n",
    "with open('glove.6B.50d.txt', 'rb') as f:  # for glove embedding\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Construct dictionary with glove\n",
    "\n",
    "trained_dict = dict()\n",
    "n = len(lines)\n",
    "for i in range(n):\n",
    "    line = lines[i].split()\n",
    "    trained_dict[line[0].decode(\"utf-8\").upper()] = [float(line[j]) for j in range(1, 51)]\n",
    "\n",
    "random_embedding = Glove_embedding(train_zip, test_zip,trained_dict=None)\n",
    "random_embedding.get_words()\n",
    "random_embedding.get_id()\n",
    "\n",
    "glove_embedding = Glove_embedding(train_zip, test_zip,trained_dict=trained_dict)\n",
    "glove_embedding.get_words()\n",
    "glove_embedding.get_id()\n",
    "\n",
    "\n",
    "iter_times = 100\n",
    "learning_rate=0.001\n",
    "batch_size=100\n",
    "\n",
    "NN_plot(random_embedding,glove_embedding,50,50,learning_rate,batch_size,iter_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
